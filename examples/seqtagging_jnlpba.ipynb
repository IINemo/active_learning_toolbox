{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies for sequence tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y libact\n",
    "!pip install git+https://github.com/IINemo/libact.git@seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y actleto\n",
    "!pip install git+https://github.com/IINemo/active_learning_toolbox.git@seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/IINemo/text_selector.git\n",
    "!cd text_selector && git pull\n",
    "!pip uninstall -y text_selector\n",
    "!pip install -e ./text_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension install --py --symlink --sys-prefix text_selector\n",
    "!jupyter nbextension enable --py --sys-prefix text_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flair\n",
    "!pip install git+https://github.com/IINemo/bert_sequence_tagger.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data\n",
    "!cd data && wget http://www.nactem.ac.uk/tsujii/GENIA/ERtask/Genia4ERtraining.tar.gz\n",
    "!cd data && wget http://www.nactem.ac.uk/tsujii/GENIA/ERtask/Genia4ERtest.tar.gz\n",
    "    \n",
    "!cd data && tar -xf ./Genia4ERtraining.tar.gz\n",
    "!cd data && tar -xf ./Genia4ERtest.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections, pandas as pd, numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from libact.query_strategies import UncertaintySampling\n",
    "\n",
    "from actleto import ActiveLearner, ActiveLearnerUiWidget, make_libact_strategy_ctor\n",
    "from actleto.annotator.visualizers.seq_annotation import SeqAnnotationVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_in_between(offsets, start, end):\n",
    "    res = []\n",
    "    for i, offset in enumerate(offsets):\n",
    "        if start <= offset and offset <= end:\n",
    "            res.append(i)\n",
    "    return res\n",
    "\n",
    "\n",
    "def convert_y_to_bio_format(X, y):\n",
    "    final_res = []\n",
    "    for i, sent_y in enumerate(y):\n",
    "        sent = X[i]\n",
    "        offsets = []\n",
    "        curr_offset = 0\n",
    "        for index, word in enumerate(sent.split(' ')):\n",
    "            offsets.append(curr_offset)\n",
    "            curr_offset += len(word) + 1\n",
    "        \n",
    "        good_ys = ['O'] * len(sent)\n",
    "        for w_y in sent_y:\n",
    "            positions = find_in_between(offsets, w_y['start'], w_y['end'])\n",
    "            good_ys[positions[0]] = 'B-' + w_y['tag']\n",
    "            \n",
    "            for pos in positions[1:]:\n",
    "                good_ys[pos] = 'I-' + w_y['tag']\n",
    "        \n",
    "        final_res.append(good_ys)\n",
    "    \n",
    "    return final_res\n",
    "\n",
    "\n",
    "def create_helper(X_train):\n",
    "    X_helper = pd.DataFrame([' '.join(e) for e in X_train], columns=['texts'])\n",
    "    return X_helper\n",
    "\n",
    "\n",
    "def convert_y_to_dict_format(X, y):\n",
    "    dict_annots = []\n",
    "    for sent_x, sent_y in zip(X, y):\n",
    "        offsets = []\n",
    "        curr_offset = 0\n",
    "        for index, word in enumerate(sent_x):\n",
    "            offsets.append(curr_offset)\n",
    "            curr_offset += len(word) + 1\n",
    "\n",
    "        sent_dict_annots = []\n",
    "        start_offset = -1\n",
    "        last_offset = -1\n",
    "        entity_tag = ''\n",
    "        for i, tag in enumerate(sent_y):\n",
    "            if tag.split('-')[0] == 'O':\n",
    "                if start_offset != -1:\n",
    "                    sent_dict_annots.append({'tag' : entity_tag, \n",
    "                                            'start' : start_offset, \n",
    "                                            'end' : last_offset})\n",
    "                start_offset = -1\n",
    "                \n",
    "            if tag.split('-')[0] == 'B':\n",
    "                if start_offset != -1:\n",
    "                    sent_dict_annots.append({'tag' : entity_tag, \n",
    "                                            'start' : start_offset, \n",
    "                                            'end' : last_offset})\n",
    "                \n",
    "                start_offset = offsets[i]\n",
    "                entity_tag = tag.split('-')[1]\n",
    "                last_offset = offsets[i] + len(sent_x[i])\n",
    "            elif tag.split('-')[0] == 'I':\n",
    "                last_offset = offsets[i] + len(sent_x[i])\n",
    "        \n",
    "        if start_offset != -1:\n",
    "            sent_dict_annots.append({'tag' : entity_tag,\n",
    "                             'start' : start_offset,\n",
    "                             'end' : last_offset})\n",
    "        \n",
    "        dict_annots.append(sent_dict_annots)\n",
    "    \n",
    "    return dict_annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_sequence_tagger.bert_utils import make_bert_tag_dict_from_flair_corpus, prepare_flair_corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "\n",
    "def prepare_corpus(corpus):\n",
    "    X, y = [], []\n",
    "    for X_i, y_i in prepare_flair_corpus(corpus):\n",
    "        X.append(X_i)\n",
    "        y.append(y_i)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "data_folder = './data/'\n",
    "corpus = ColumnCorpus(data_folder, {0 : 'text', 1 : 'ner'},\n",
    "                                train_file='Genia4ERtask1.iob2',\n",
    "                                test_file='Genia4EReval1.iob2',\n",
    "                                dev_file='Genia4EReval1.iob2') # We do not need dev set\n",
    "\n",
    "tags_vals, tag2idx = make_bert_tag_dict_from_flair_corpus(corpus)\n",
    "    \n",
    "X_train, y_train = prepare_corpus(corpus.train)\n",
    "X_test, y_test = prepare_corpus(corpus.test)\n",
    "\n",
    "\n",
    "y_train_dict = convert_y_to_dict_format(X_train, y_train)\n",
    "X_helper = create_helper(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(set((tag.split('-')[1] for tag in tags_vals if len(tag.split('-')) > 1)))\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample seed elements for emulated training\n",
    "\n",
    "import random\n",
    "\n",
    "sample_size = 100\n",
    "random_sample = random.sample(list(range(len(y_train))), sample_size)\n",
    "\n",
    "y_seed_dict = [None for _ in range(len(y_train_dict))]\n",
    "\n",
    "for elem in random_sample:\n",
    "    y_seed_dict[elem] = y_train_dict[elem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model and active learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libact.base.interfaces import ProbabilisticModel\n",
    "from libact.base.dataset import Dataset\n",
    "from libact.query_strategies import RandomSampling\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections.abc import Iterable  \n",
    "import gc\n",
    "\n",
    "\n",
    "class LibActNN(ProbabilisticModel):\n",
    "    def __init__(self, \n",
    "                 model_ctor, \n",
    "                 trainer_ctor,\n",
    "                 batch_size=16,\n",
    "                 bs_pred=256, \n",
    "                 retrain_epochs=3, \n",
    "                 iter_retrain=1,\n",
    "                 train_from_scratch=True, \n",
    "                 valid_ratio=0.25,\n",
    "                 string_input=True):\n",
    "        self._model_ctor = model_ctor\n",
    "        self._trainer_ctor = trainer_ctor\n",
    "        self._model = None\n",
    "        self._trainer = None\n",
    "        self._batch_size = batch_size\n",
    "        self._bs_pred = bs_pred\n",
    "        self._retrain_epochs = retrain_epochs\n",
    "        self._batch_size = batch_size\n",
    "        self._iter_retrain = iter_retrain\n",
    "        self._train_from_scratch = train_from_scratch\n",
    "        self._valid_ratio = valid_ratio\n",
    "        self._string_input = string_input\n",
    "        \n",
    "        self._iter = 0\n",
    "        \n",
    "    def _predict_core(self, X):\n",
    "        if self._string_input:\n",
    "            X = [sent.split(' ') for sent in X]\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "        return self._model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return np.asarray(self._predict_core(X)[1]).reshape(-1, 1)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self._predict_core(X)[0]\n",
    "    \n",
    "    def train(self, libact_dataset, new_indexes=None):\n",
    "        torch.cuda.empty_cache()\n",
    "        collate_fn = lambda inpt: tuple(zip(*inpt))\n",
    "        \n",
    "        if (new_indexes is not None) and (self._iter % self._iter_retrain) != 0:\n",
    "            libact_dataset = Dataset([libact_dataset.data[i][0] for i in new_indexes], \n",
    "                                     [libact_dataset.data[i][1] for i in new_indexes])\n",
    "            n_epochs = 1\n",
    "        else:\n",
    "            n_epochs = self._retrain_epochs\n",
    "            \n",
    "        X, y = libact_dataset.format_sklearn()\n",
    "        if self._string_input:\n",
    "            y = convert_y_to_bio_format(X, y)\n",
    "            X = [s.split(' ') for s in X]\n",
    "        \n",
    "        if self._valid_ratio > 0.:\n",
    "            X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=self._valid_ratio)\n",
    "            valid_data = list(zip(X_valid, y_valid))\n",
    "        else:\n",
    "            X_train, y_train = X, y\n",
    "            valid_data = None\n",
    "        \n",
    "        train_data = list(zip(X_train, y_train))\n",
    "        \n",
    "        if (self._model is None) or self._train_from_scratch:\n",
    "            self._model = self._model_ctor()\n",
    "            self._trainer = self._trainer_ctor(self._model, len(X_train), \n",
    "                                               train_data, valid_data)\n",
    "\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        self._trainer.train(self._retrain_epochs)\n",
    "        \n",
    "        self._iter += 1\n",
    "        \n",
    "    def score(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_sequence_tagger import BertForTokenClassificationCustom, SequenceTaggerBert, ModelTrainerBert\n",
    "from bert_sequence_tagger.bert_utils import get_parameters_without_decay, get_model_parameters\n",
    "from bert_sequence_tagger.metrics import f1_entity_level\n",
    "\n",
    "from pytorch_transformers import BertTokenizer, AdamW\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "CACHE_DIR = 'cache'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 100\n",
    "PRED_BATCH_SIZE = 1500\n",
    "random_state = 2019\n",
    "N_EPOCHS = 3\n",
    "\n",
    "EARLY_STOPPING = 1\n",
    "N_SAMPLES_PER_AL_ITER = 30\n",
    "LEARNING_RATE = 5e-5\n",
    "VALIDATION_RATIO = 0.1\n",
    "\n",
    "ANNEAL_FACTOR = 0.5\n",
    "PATIENCE = 2\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "BERT_MODEL = 'bert-base-cased'\n",
    "\n",
    "\n",
    "BERT_TOKENIZER = BertTokenizer.from_pretrained(BERT_MODEL, \n",
    "                                               cache_dir=CACHE_DIR, \n",
    "                                               do_lower_case=BERT_MODEL.endswith('uncased'))\n",
    "\n",
    "\n",
    "def model_ctor():\n",
    "    model = BertForTokenClassificationCustom.from_pretrained(BERT_MODEL,\n",
    "                                                             cache_dir=CACHE_DIR, \n",
    "                                                             num_labels=len(tag2idx)).cuda()\n",
    "    seq_tagger = SequenceTaggerBert(model, BERT_TOKENIZER, idx2tag=tags_vals, \n",
    "                                    tag2idx=tag2idx, pred_batch_size=PRED_BATCH_SIZE)\n",
    "    return seq_tagger\n",
    "\n",
    "\n",
    "def trainer_ctor(seq_tagger, corpus_len, train_data, val_data):\n",
    "    optimizer = AdamW(get_model_parameters(seq_tagger._bert_model),\n",
    "                      lr=LEARNING_RATE, betas=(0.9, 0.999), \n",
    "                      eps=1e-6, weight_decay=0.01, correct_bias=True)\n",
    "\n",
    "    lr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=ANNEAL_FACTOR, patience=PATIENCE)\n",
    "    \n",
    "    trainer = ModelTrainerBert(model=seq_tagger, \n",
    "                               optimizer=optimizer, \n",
    "                               lr_scheduler=lr_scheduler,\n",
    "                               train_dataset=train_data, \n",
    "                               val_dataset=None,\n",
    "                               validation_metrics=[f1_entity_level],\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               update_scheduler='ee',\n",
    "                               keep_best_model=False,\n",
    "                               max_grad_norm=1.)\n",
    "    #validation_metrics=[f1_entity_level],\n",
    "    #decision_metric=lambda metrics: metrics[0]\n",
    "    #restore_bm_on_lr_change=False\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learn_alg_ctor = make_libact_strategy_ctor(lambda trn_ds:\n",
    "                                                  UncertaintySampling(trn_ds,\n",
    "                                                                      model = LibActNN(model_ctor=model_ctor, \n",
    "                                                                                       trainer_ctor=trainer_ctor,\n",
    "                                                                                       valid_ratio=VALIDATION_RATIO,\n",
    "                                                                                       retrain_epochs=N_EPOCHS)),\n",
    "                                                  max_samples_number=N_SAMPLES_PER_AL_ITER)\n",
    "\n",
    "# Creating ActiveLearning object that implements AL logic.\n",
    "active_learner = ActiveLearner(active_learn_alg_ctor=active_learn_alg_ctor,\n",
    "                               X_full_dataset=X_helper.texts.tolist(),\n",
    "                               y_full_dataset=y_seed_dict,\n",
    "                               rnd_start_steps=1)\n",
    "\n",
    "active_learner.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating widget for annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This try-catch block is needed to stop autosave thread in \n",
    "#case we invoke the cell multiple times.\n",
    "try:\n",
    "    if active_learn_ui:\n",
    "        active_learn_ui.stop()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Creaing the active learner widget itself and configure \n",
    "# it with active_learner, X_helper.\n",
    "active_learn_ui = ActiveLearnerUiWidget(active_learner=active_learner,\n",
    "                                        X_helper=X_helper,\n",
    "                                        display_feature_table=False,\n",
    "                                        drop_labels=[],\n",
    "                                        y_labels=None,\n",
    "                                        save_path='./jnlpba.npy',\n",
    "                                        save_time=120, \n",
    "                                        visualizer=SeqAnnotationVisualizer(tags=tags))\n",
    "\n",
    "active_learn_ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "012b7ff2636e4ff2929afd8230a6b225": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "02b7a355ee7445af818aa6a56f7ede0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2bddb62c7d014abe9a06da44227b9bc8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Save",
       "layout": "IPY_MODEL_fc95a1be1ebc4a56bca855d00efc2169",
       "style": "IPY_MODEL_7c2c262a63f5492c8fe5a2e2c442ad07"
      }
     },
     "2d171063d6af4a87a8b00ff7c33f2fbf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "33a300b6e38e47ea9869bc8309162378": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8271b9901a88424c9c29da89bcdcc866",
        "IPY_MODEL_db7c1844ff3946e29b51d200ab72a49c",
        "IPY_MODEL_ea3105f5013a4240abc562f92119415d"
       ],
       "layout": "IPY_MODEL_9841d6098a844ed8a14e1d42a0264a56"
      }
     },
     "3de00db997a343c1964215bd8c43de37": {
      "model_module": "text_selector",
      "model_module_version": "^0.0.0",
      "model_name": "TSWidgetModel",
      "state": {
       "_model_module_version": "^0.0.0",
       "_view_module_version": "^0.0.0",
       "layout": "IPY_MODEL_873d27630ace4c19bc4a04968fe137fd",
       "res": [
        "aaa"
       ],
       "tags": [
        "protein",
        "DNA",
        "cell_type",
        "cell_line",
        "RNA"
       ],
       "txts": [
        "As detected by in vivo footprinting , priming markedly increases the activation-dependent engagement of the P0 and P1 NFAT-binding elements of the IL-4 promoter .",
        "Binding parameters of [ 3H ] pyrilamine binding were Kd = 5.53 nM and Bmax = 2 , 647 sites/cell .",
        "PDBu-treated HL-60 cells remained viable for 7 days and thereafter began to die via apoptosis , with a concomitant down-regulation of Bcl-xL .",
        "Human RAR alpha was expressed in H9 , U937 and THP-1 cells , but almost undetectable in CEM cells .",
        "No increase in TGF-beta mRNA was observed ."
       ]
      }
     },
     "56a8c82dbbd04f2bba722806c440b1ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9cb589e8535b402ab4d031a1b1b68537",
        "IPY_MODEL_62c09e2fbc894017ad2f897bdac69f5a"
       ],
       "layout": "IPY_MODEL_02b7a355ee7445af818aa6a56f7ede0e"
      }
     },
     "6016917868fe4cfca53920851c30bcb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "62c09e2fbc894017ad2f897bdac69f5a": {
      "model_module": "text_selector",
      "model_module_version": "^0.0.0",
      "model_name": "TSWidgetModel",
      "state": {
       "_model_module_version": "^0.0.0",
       "_view_module_version": "^0.0.0",
       "layout": "IPY_MODEL_2d171063d6af4a87a8b00ff7c33f2fbf",
       "res": [
        "aaa"
       ],
       "tags": [
        "protein",
        "DNA",
        "cell_type",
        "cell_line",
        "RNA"
       ],
       "txts": [
        "As detected by in vivo footprinting , priming markedly increases the activation-dependent engagement of the P0 and P1 NFAT-binding elements of the IL-4 promoter .",
        "Binding parameters of [ 3H ] pyrilamine binding were Kd = 5.53 nM and Bmax = 2 , 647 sites/cell .",
        "PDBu-treated HL-60 cells remained viable for 7 days and thereafter began to die via apoptosis , with a concomitant down-regulation of Bcl-xL .",
        "Human RAR alpha was expressed in H9 , U937 and THP-1 cells , but almost undetectable in CEM cells .",
        "No increase in TGF-beta mRNA was observed ."
       ]
      }
     },
     "65e267fca04f48b2ae0463051495c272": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_ba06e045de7c49e99e82394a074f3c70",
       "style": "IPY_MODEL_012b7ff2636e4ff2929afd8230a6b225",
       "value": "Iteration#..."
      }
     },
     "6d20dd66e4c54515bd8630a4b5628255": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_33a300b6e38e47ea9869bc8309162378",
        "IPY_MODEL_3de00db997a343c1964215bd8c43de37"
       ],
       "layout": "IPY_MODEL_827111bd3e5f4004be5c8cdae33ec8ac"
      }
     },
     "7c2c262a63f5492c8fe5a2e2c442ad07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "827111bd3e5f4004be5c8cdae33ec8ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8271b9901a88424c9c29da89bcdcc866": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Next Iteration",
       "icon": "clock-o",
       "layout": "IPY_MODEL_eb638749231647e494aa80cf28b0c35a",
       "style": "IPY_MODEL_fcbfcb7a62ff44f1b44b6d6fd38075a8"
      }
     },
     "873d27630ace4c19bc4a04968fe137fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "87e6c275162b4a53bc940dba9c0044a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9841d6098a844ed8a14e1d42a0264a56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9cb589e8535b402ab4d031a1b1b68537": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_be788141dae8484bae65354f63c3c82b",
        "IPY_MODEL_65e267fca04f48b2ae0463051495c272",
        "IPY_MODEL_2bddb62c7d014abe9a06da44227b9bc8"
       ],
       "layout": "IPY_MODEL_87e6c275162b4a53bc940dba9c0044a5"
      }
     },
     "a42e2142f28a441bb37db5cc94ebaa24": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "ab5d55e09f8c4e669ad89bd0cdaf2bfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "ba06e045de7c49e99e82394a074f3c70": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bd4a12b7f207479297f136238950aba6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "be788141dae8484bae65354f63c3c82b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Next Iteration",
       "icon": "clock-o",
       "layout": "IPY_MODEL_fd4f46c9ddcd4084a024a34ee6217894",
       "style": "IPY_MODEL_ab5d55e09f8c4e669ad89bd0cdaf2bfe"
      }
     },
     "d30506af0b0a48adbfef87387a9fc956": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "db7c1844ff3946e29b51d200ab72a49c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_bd4a12b7f207479297f136238950aba6",
       "style": "IPY_MODEL_6016917868fe4cfca53920851c30bcb7",
       "value": "Iteration#..."
      }
     },
     "ea3105f5013a4240abc562f92119415d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Save",
       "layout": "IPY_MODEL_d30506af0b0a48adbfef87387a9fc956",
       "style": "IPY_MODEL_a42e2142f28a441bb37db5cc94ebaa24"
      }
     },
     "eb638749231647e494aa80cf28b0c35a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fc95a1be1ebc4a56bca855d00efc2169": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fcbfcb7a62ff44f1b44b6d6fd38075a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "fd4f46c9ddcd4084a024a34ee6217894": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
